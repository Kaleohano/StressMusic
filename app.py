from flask import Flask, render_template, request, jsonify, send_file
import os
import uuid
from datetime import datetime, timedelta
import threading
import time
import shutil

# å¯¼å…¥æˆ‘ä»¬ç°æœ‰çš„æ¨¡å—
from stress import get_stress_music_prompt, STRESS_MUSIC_MAP
import json
import re
import scipy
import torch
import numpy as np
import scipy.signal
from transformers import AutoProcessor, MusicgenForConditionalGeneration
import subprocess
import sys

app = Flask(__name__)

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
model = None
processor = None
model_loaded = False

# æµ‹é‡è¿›ç¨‹çŠ¶æ€ï¼ˆåœ¨å†…å­˜ä¸­è·Ÿè¸ªï¼‰
measurement_state = {
    'running': False,
    'finished': False,
    'error': None,
    'output': ''
}
measurement_proc = None
watcher_proc = None

def load_model():
    """åœ¨åå°åŠ è½½æ¨¡å‹"""
    global model, processor, model_loaded
    try:
        print("ğŸµ å¼€å§‹åŠ è½½éŸ³ä¹ç”Ÿæˆæ¨¡å‹...")
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        model_path = "/Users/xibei/MusicGPT/model"
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            print("ğŸ’¡ è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²æ­£ç¡®ä¸‹è½½å¹¶æ”¾ç½®åˆ°æŒ‡å®šè·¯å¾„")
            model_loaded = False
            return
        
        # æ£€æŸ¥å¿…è¦çš„æ¨¡å‹æ–‡ä»¶
        required_files = ["config.json", "pytorch_model.bin", "preprocessor_config.json"]
        missing_files = []
        for file in required_files:
            file_path = os.path.join(model_path, file)
            if not os.path.exists(file_path):
                missing_files.append(file)
                print(f"âŒ ç¼ºå°‘æ¨¡å‹æ–‡ä»¶: {file}")
        
        if missing_files:
            print(f"ğŸ’¡ ç¼ºå°‘ä»¥ä¸‹æ¨¡å‹æ–‡ä»¶: {', '.join(missing_files)}")
            print("ğŸ’¡ è¯·ä¸‹è½½å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶")
            model_loaded = False
            return
        
        print("ğŸ“¦ æ­£åœ¨åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹...")
        # å¼ºåˆ¶ä½¿ç”¨ CPU ä»¥ä¿®å¤ MPS äº§ç”Ÿçš„"å¤§é£å¹"å™ªå£°é—®é¢˜
        # è™½ç„¶ MPS ç†è®ºä¸Šæ›´å¿«ï¼Œä½†åœ¨å½“å‰ PyTorch/MusicGen ç»„åˆä¸‹è¾“å‡ºå¯èƒ½æ˜¯çº¯å™ªå£°
        device = "cpu"
        print(f"ğŸ–¥ï¸  å¼ºåˆ¶ä½¿ç”¨è®¾å¤‡: {device} (ä¸ºäº†ä¿è¯éŸ³è´¨ç»å¯¹ç¨³å®šï¼Œæ”¾å¼ƒ GPU åŠ é€Ÿ)")
        
        # è¿™é‡Œçš„æ—§ä»£ç å·²æ³¨é‡Šï¼Œå› ä¸º MPS ç¡®å®ä¸å¯ç”¨
        # if torch.cuda.is_available(): ...
            
        processor = AutoProcessor.from_pretrained(model_path)
        model = MusicgenForConditionalGeneration.from_pretrained(model_path).to(device)
        
        # éªŒè¯æ¨¡å‹åŠ è½½æ˜¯å¦æˆåŠŸ
        if processor is None or model is None:
            raise Exception("æ¨¡å‹æˆ–å¤„ç†å™¨åŠ è½½å¤±è´¥")
        
        model_loaded = True
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
        print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯: {model.config}")
        
    except FileNotFoundError as e:
        print(f"âŒ æ¨¡å‹æ–‡ä»¶é”™è¯¯: {e}")
        model_loaded = False
    except ImportError as e:
        print(f"âŒ ä¾èµ–åº“é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£… transformers å’Œ torch åº“")
        model_loaded = False
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ å¯èƒ½çš„åŸå› ï¼šæ¨¡å‹æ–‡ä»¶æŸåã€å†…å­˜ä¸è¶³ã€CUDAé”™è¯¯ç­‰")
        model_loaded = False

# åœ¨åº”ç”¨å¯åŠ¨æ—¶å¼€å§‹åŠ è½½æ¨¡å‹
threading.Thread(target=load_model, daemon=True).start()

# åˆ›å»ºéŸ³é¢‘æ–‡ä»¶å­˜å‚¨ç›®å½•
AUDIO_DIR = "generated_audio"
if not os.path.exists(AUDIO_DIR):
    os.makedirs(AUDIO_DIR)

# æ–‡ä»¶ç®¡ç†é…ç½®
MAX_AUDIO_FILES = 50  # æœ€å¤§éŸ³é¢‘æ–‡ä»¶æ•°é‡
CLEANUP_INTERVAL = 3600  # æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰
AUDIO_RETENTION_HOURS = 24  # éŸ³é¢‘æ–‡ä»¶ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰

def cleanup_old_files():
    """æ¸…ç†æ—§çš„éŸ³é¢‘æ–‡ä»¶"""
    try:
        if not os.path.exists(AUDIO_DIR):
            return
        
        current_time = datetime.now()
        files = os.listdir(AUDIO_DIR)
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„æ–‡ä»¶
        audio_files = []
        for file in files:
            if file.endswith('.wav'):
                file_path = os.path.join(AUDIO_DIR, file)
                mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                audio_files.append((file_path, mtime))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        audio_files.sort(key=lambda x: x[1])
        
        # åˆ é™¤è¶…è¿‡ä¿ç•™æ—¶é—´çš„æ–‡ä»¶
        for file_path, mtime in audio_files:
            if current_time - mtime > timedelta(hours=AUDIO_RETENTION_HOURS):
                try:
                    os.remove(file_path)
                    print(f"å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path}")
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # å¦‚æœæ–‡ä»¶æ•°é‡ä»ç„¶è¶…è¿‡é™åˆ¶ï¼Œåˆ é™¤æœ€æ—§çš„æ–‡ä»¶
        remaining_files = [f for f in os.listdir(AUDIO_DIR) if f.endswith('.wav')]
        if len(remaining_files) > MAX_AUDIO_FILES:
            excess_count = len(remaining_files) - MAX_AUDIO_FILES
            for i in range(excess_count):
                try:
                    os.remove(os.path.join(AUDIO_DIR, remaining_files[i]))
                    print(f"å·²åˆ é™¤è¶…é‡æ–‡ä»¶: {remaining_files[i]}")
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {remaining_files[i]}: {e}")
                    
    except Exception as e:
        print(f"æ¸…ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def start_cleanup_scheduler():
    """å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡"""
    def cleanup_loop():
        while True:
            time.sleep(CLEANUP_INTERVAL)
            cleanup_old_files()
    
    cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
    cleanup_thread.start()
    print("æ–‡ä»¶æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")


def _run_measurement_in_thread(cmd, state_dict):
    """åœ¨åå°çº¿ç¨‹å†…æ‰§è¡Œæµ‹é‡å‘½ä»¤å¹¶æ›´æ–°çŠ¶æ€å­—å…¸ã€‚
    
    ä½¿ç”¨ subprocess æ‰§è¡Œ hrv_reader.pyï¼Œå¹¶å®æ—¶æ•è·è¾“å‡ºã€‚
    """
    global measurement_proc
    try:
        # å¯åŠ¨å­è¿›ç¨‹ï¼Œè¡Œç¼“å†²
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )
        measurement_proc = process
        
        state_dict.update({'running': True, 'finished': False, 'error': None, 'output': 'æ­£åœ¨å¯åŠ¨ä¼ æ„Ÿå™¨...'})
        
        # æŒç»­è¯»å–è¾“å‡º
        for line in iter(process.stdout.readline, ''):
            if line:
                line = line.strip()
                if line:
                    state_dict['output'] = line
                    # å¯é€‰ï¼šæ‰“å°åˆ°åå°æ§åˆ¶å°
                    print(f"[HRV] {line}")
        
        process.wait()
        ret = process.returncode
        
        state_dict['running'] = False
        state_dict['finished'] = True
        if ret != 0:
            err = f"è¿›ç¨‹å¼‚å¸¸é€€å‡º (code {ret})"
            state_dict['error'] = err
            state_dict['output'] = err
        else:
            state_dict['output'] = "æµ‹é‡å·²ç»“æŸ"
            
    except Exception as e:
        state_dict['error'] = str(e)
        state_dict['running'] = False
        state_dict['finished'] = True
        print(f"å¯åŠ¨ HRV æµ‹é‡å¤±è´¥: {e}")
    finally:
        measurement_proc = None


def _persist_stress_map(stress_map):
    """å°†ç»™å®šçš„ STRESS_MUSIC_MAP å†™å›åˆ° stress.pyï¼ˆå¤‡ä»½åŸæ–‡ä»¶ï¼‰ã€‚"""
    stress_path = os.path.join(os.path.dirname(__file__), 'stress.py')
    try:
        # è¯»å–åŸæ–‡ä»¶å†…å®¹
        with open(stress_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ„å»ºæ–°çš„ STRESS_MUSIC_MAP æ–‡æœ¬ï¼ˆä¿æŒå¯è¯»çš„ Python å­—é¢é‡æ ¼å¼ï¼‰
        entries = []
        for key, lst in stress_map.items():
            vals = ', '.join([f'"{s}"' for s in lst])
            entries.append(f'    "{key}": [{vals}]')
        new_map_text = 'STRESS_MUSIC_MAP = {\n' + ',\n'.join(entries) + '\n}\n'

        # ä½¿ç”¨æ­£åˆ™æ›¿æ¢åŸ MAP å—ï¼ˆéè´ªå©ªï¼‰ï¼Œè‹¥ä¸å­˜åœ¨åˆ™åœ¨æ–‡ä»¶é¡¶éƒ¨æ’å…¥
        pattern = r"(?m)^STRESS_MUSIC_MAP\s*=\s*\{[\s\S]*?\}"
        new_content, n = re.subn(pattern, new_map_text.rstrip('\n'), content, count=1)
        if n == 0:
            # æœªæ‰¾åˆ°ç°æœ‰å®šä¹‰ï¼Œå°†æ–°å®šä¹‰æ’å…¥æ–‡ä»¶å¼€å¤´å¹¶ä¿ç•™åŸæ³¨é‡Š/å¯¼å…¥
            new_content = new_map_text + '\n' + content

        # å¤‡ä»½å¹¶ä»¥åŸå­æ–¹å¼å†™å…¥æ–°æ–‡ä»¶ï¼šå…ˆå†™åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½åæ›¿æ¢
        backup_path = stress_path + '.bak'
        with open(backup_path, 'w', encoding='utf-8') as f:
            f.write(content)

        tmp_path = stress_path + '.tmp'
        with open(tmp_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        # åŸå­æ›¿æ¢
        os.replace(tmp_path, stress_path)
        return True, None
    except Exception as e:
        return False, str(e)


def update_and_persist_preference(pref):
    """å°†åå¥½ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰æ˜ å°„ä¸ºå…³é”®è¯ï¼Œæ›´æ–° USER_MUSIC_PREFERENCE å˜é‡å¹¶æŒä¹…åŒ–åˆ°JSONæ–‡ä»¶ï¼ˆä¸ä¿®æ”¹stress.pyï¼‰ã€‚
    è¿”å› (success, message_or_pref_word)
    """
    from stress import set_user_music_preference
    
    mapping = {
        'æµè¡Œ': 'pop', 'æ‘‡æ»š': 'rock', 'å¤å…¸': 'classical',
        'pop': 'pop', 'rock': 'rock', 'classical': 'classical',
        'å˜»å“ˆ': 'hip hop', 'ç”µå­': 'electronic', 'R&B': 'r&b',
        'çˆµå£«': 'jazz', 'ä¹¡æ‘': 'country', 'å¸ƒé²æ–¯': 'blues', 'é›·é¬¼': 'reggae'
    }
    pref_word = mapping.get(pref, None)
    if pref_word is None:
        return False, f'ä¸æ”¯æŒçš„åå¥½: {pref}'

    # ä½¿ç”¨æ–°çš„å‡½æ•°è®¾ç½®ç”¨æˆ·åå¥½ï¼ˆè¿™ä¼šæ›´æ–° USER_MUSIC_PREFERENCE å˜é‡å¹¶æŒä¹…åŒ–åˆ°JSONæ–‡ä»¶ï¼‰
    success = set_user_music_preference(pref_word)
    if success:
        return True, pref_word
    else:
        return False, f'è®¾ç½®åå¥½å¤±è´¥: {pref_word}'

# å¯åŠ¨æ–‡ä»¶æ¸…ç†ä»»åŠ¡
start_cleanup_scheduler()

@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    return render_template('index.html')

@app.route('/api/stress-levels')
def get_stress_levels():
    """è·å–å¯ç”¨çš„å‹åŠ›æ°´å¹³é€‰é¡¹"""
    return jsonify(list(STRESS_MUSIC_MAP.keys()))

@app.route('/api/model-status')
def model_status():
    """æ£€æŸ¥æ¨¡å‹åŠ è½½çŠ¶æ€"""
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£åœ¨åŠ è½½ä¸­ï¼ˆé€šè¿‡æ£€æŸ¥çº¿ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œï¼‰
    # å¦‚æœ model_loaded ä¸º False ä¸” model å’Œ processor éƒ½ä¸º Noneï¼Œè¯´æ˜è¿˜åœ¨åŠ è½½ä¸­
    is_loading = not model_loaded and (model is None or processor is None)
    
    status_info = {
        'loaded': model_loaded,
        'loading': is_loading,
        'status': 'ready' if model_loaded else ('loading' if is_loading else 'not_started'),
        'message': 'æ¨¡å‹å·²å°±ç»ª' if model_loaded else ('æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨å€™...' if is_loading else 'æ¨¡å‹å°šæœªå¼€å§‹åŠ è½½')
    }
    
    # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæä¾›æ›´å¤šä¿¡æ¯
    if not model_loaded and not is_loading:
        status_info['error'] = True
        status_info['suggestion'] = 'å»ºè®®æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„æˆ–é‡æ–°å¯åŠ¨åº”ç”¨'
    
    return jsonify(status_info)

# å…¨å±€å˜é‡æ§åˆ¶ç”ŸæˆçŠ¶æ€
music_generation_status = {
    'status': 'idle', # idle, processing, completed, failed
    'file_id': None,
    'error': None
}

# å¯ç”¨ MPS åå¤‡æ¨¡å¼ï¼Œä»¥é˜²éƒ¨åˆ†ç®—å­åœ¨ GPU ä¸Šä¸æ”¯æŒ
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
# è§£é™¤ MPS æ˜¾å­˜é™åˆ¶ (å…è®¸ä½¿ç”¨æ›´å¤šç³»ç»Ÿå†…å­˜)ï¼Œé¿å… OOM
os.environ["PYTORCH_MPS_HIGH_WATERMARK_RATIO"] = "0.0"

import uuid
from datetime import datetime, timedelta
import threading
import time
import shutil
import gc  # å¼•å…¥åƒåœ¾å›æ”¶

# ... (imports) ...

def generate_music_task(input_text):
    global music_generation_status
    print(f"ğŸ§µ åå°çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”ŸæˆéŸ³ä¹ï¼Œæç¤ºè¯: {input_text}")
    try:
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if model is None or processor is None:
            raise Exception("æ¨¡å‹æœªæ­£ç¡®åŠ è½½")

        # æ¯è½®ç”Ÿæˆå‰ä¸»åŠ¨æ¸…ç†å†…å­˜
        gc.collect()
        if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            torch.mps.empty_cache()

        # è·å–å½“å‰é…ç½®çš„è®¾å¤‡
        original_device = model.device
        
        # ä½¿ç”¨ inference_mode æé™å‹æ¦¨ CPU æ€§èƒ½
        with torch.inference_mode():
            try:
                print(f"ğŸš€ å°è¯•åœ¨ {original_device} ä¸Šç”Ÿæˆ...")
                inputs = processor(
                    text=[input_text],
                    return_tensors="pt"
                ).to(original_device)
                
                audio_values = model.generate(
                    **inputs,
                    max_new_tokens=1250,
                    do_sample=True,
                    guidance_scale=3.0,
                    temperature=0.8,
                    top_p=0.9
                )
            except RuntimeError as e:
                print(f"âš ï¸ ç¡¬ä»¶åŠ é€Ÿç”Ÿæˆå¤±è´¥ ({e})")
                print("ğŸ”„ æ­£åœ¨è‡ªåŠ¨å›é€€åˆ° CPU é‡è¯•...")
                
                model.to('cpu')
                inputs = processor(text=[input_text], return_tensors="pt").to('cpu')
                audio_values = model.generate(
                    **inputs,
                    max_new_tokens=1250,
                    do_sample=True,
                    guidance_scale=3.0,
                    temperature=0.8,
                    top_p=0.9
                )
                if original_device.type != 'cpu':
                    try: model.to(original_device)
                    except: pass

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        file_id = str(uuid.uuid4())
        output_file = os.path.join(AUDIO_DIR, f"{file_id}.wav")
        
        sampling_rate = model.config.audio_encoder.sampling_rate
        # å¿…é¡»å…ˆç§»å› CPU
        audio_data = audio_values[0, 0].cpu().numpy()
        
        # --- ä¼˜åŒ–ï¼šå»é™¤ç›´æµåç§» (DC Offset)ï¼Œé˜²æ­¢æ‹¼æ¥æ—¶çš„"å™—"å£° ---
        if len(audio_data) > 0:
            audio_data = audio_data - np.mean(audio_data)
        
        if len(audio_data) == 0:
            raise ValueError("ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®ä¸ºç©º")

        # --- ç­–ç•¥ï¼šDSP å˜å¥å¾ªç¯ (A-B-A-B ç»“æ„) ---
        target_duration = 300  # 5 åˆ†é’Ÿ
        current_duration = len(audio_data) / sampling_rate
        
        if current_duration > 0 and current_duration < target_duration:
            print(f"ğŸ”„ æ­£åœ¨åº”ç”¨ Overlap-Add æ— ç¼é‡å æ‹¼æ¥ç­–ç•¥ (Duration: {current_duration:.2f}s)...")
            
            # 1. å‡†å¤‡ç´ æ: A (åŸç‰ˆ) å’Œ B (å˜å¥)
            # åˆ¶ä½œ B æ®µ (å˜å¥)ï¼šæ–½åŠ æŸ”å’Œçš„ä½é€šæ»¤æ³¢å™¨
            try:
                b, a = scipy.signal.butter(4, 1200 / (sampling_rate / 2), 'low')
                audio_data_lowpass = scipy.signal.lfilter(b, a, audio_data)
                if np.isnan(audio_data_lowpass).any(): audio_data_lowpass = audio_data.copy() 
            except:
                audio_data_lowpass = audio_data.copy()

            # 2. å®šä¹‰é‡å å‚æ•°
            overlap_sec = 3.0 # 3ç§’é‡å 
            overlap_len = int(sampling_rate * overlap_sec)
            
            # --- å…³é”®ä¿®å¤ï¼šé˜²æ­¢éŸ³é¢‘è¿‡å¯¼è‡´ Overlap å´©æºƒ ---
            # é‡åˆ°"å®ä¸€å£°"å°±æ˜¯å› ä¸ºéŸ³é¢‘è¿˜æ²¡ overlap é•¿ï¼Œå¯¼è‡´åˆ‡ç‰‡ç´¢å¼•é”™ä¹±
            min_required_len = int(sampling_rate * 5.0) # è‡³å°‘è¦æœ‰5ç§’æ‰èƒ½åšæ¼‚äº®çš„ fade
            if len(audio_data) < min_required_len:
                print(f"âš ï¸ ç”ŸæˆéŸ³é¢‘è¿‡çŸ­ ({len(audio_data)/sampling_rate:.2f}s)ï¼Œæ­£åœ¨å¼ºåˆ¶è¡¥é½...")
                # ç®€å•é‡å¤å‡ æ¬¡ç›´åˆ°è¶³å¤Ÿé•¿ï¼Œä¿è¯åç»­ç®—æ³•ä¸å´©
                if len(audio_data) > 0:
                    repeat_times = int(np.ceil(min_required_len / len(audio_data)))
                    audio_data = np.tile(audio_data, repeat_times)
                    # åŒæ—¶ä¹Ÿè¡¥é½ B æ®µ
                    audio_data_lowpass = np.tile(audio_data_lowpass, repeat_times)
            
            # å¦‚æœè¿˜æ˜¯ä¸å¤Ÿé•¿ï¼ˆæå°æ¦‚ç‡ï¼‰ï¼Œç¼©å° Overlap
            if len(audio_data) < 2 * overlap_len:
                overlap_len = len(audio_data) // 3
            # ---------------------------------------------
            
            # 3. é¢„è®¡ç®—æ·¡å…¥æ·¡å‡ºæ›²çº¿ (ç”¨äºé‡å åŒº)
            # ä½¿ç”¨ sqrt(t) æ›²çº¿ï¼Œä¿è¯åŠŸç‡æ’å®š (Constant Power Crossfade)
            t = np.linspace(0, 1, overlap_len)
            fade_in = np.sqrt(t)
            fade_out = np.sqrt(1 - t)
            
            # 4. å¼€å§‹æ‹¼æ¥
            # è®¡ç®—æ€»å…±éœ€è¦å¤šå°‘æ®µ
            # æ¯ä¸€æ®µè´¡çŒ®çš„æœ‰æ•ˆæ–°é•¿åº¦æ˜¯ (Length - Overlap)
            segment_len = len(audio_data)
            hop_len = segment_len - overlap_len
            if hop_len <= 0: hop_len = segment_len // 2 # é˜²å¾¡æ€§ç¼–ç 

            target_samples = int(target_duration * sampling_rate)
            num_segments = int(np.ceil(target_samples / hop_len)) + 2
            
            # åˆå§‹åŒ–å¤§æ•°ç»„
            # é¢„ä¼°ä¸€ä¸ªè¶³å¤Ÿé•¿çš„é•¿åº¦ï¼Œæœ€åå†æˆªæ–­
            estimated_len = hop_len * num_segments + segment_len
            combined_audio = np.zeros(estimated_len, dtype=np.float32)
            
            print(f"ğŸ§© æ­£åœ¨æ‹¼æ¥ {num_segments} ä¸ªç‰‡æ®µï¼Œé‡å é•¿åº¦: {overlap_len} é‡‡æ ·ç‚¹")

            for i in range(num_segments):
                # é€‰æ‹©ç´ æ: A-B-A-B
                part = audio_data if i % 2 == 0 else audio_data_lowpass
                
                # è·å–å½“å‰æ®µåœ¨æ€»æ•°ç»„ä¸­çš„ä½ç½®
                # ç¬¬ i æ®µçš„èµ·å§‹ä½ç½®ç”± hop_len å†³å®š
                start = i * hop_len
                
                # å¤åˆ¶ä¸€ä»½å½“å‰ç‰‡æ®µ
                this_segment = part.copy()
                
                # å¦‚æœè¿™ä¸æ˜¯ç¬¬ä¸€æ®µï¼Œå¼€å¤´è¦ Fade In (ä¸ºäº†å’Œä¸Šä¸€æ®µçš„ Tail èåˆ)
                if i > 0:
                     this_segment[:overlap_len] *= fade_in
                
                # å¦‚æœè¿™ä¸æ˜¯æœ€åä¸€æ®µï¼Œç»“å°¾è¦ Fade Out (ä¸ºäº†å’Œä¸‹ä¸€æ®µçš„ Head èåˆ)
                if i < num_segments - 1:
                     this_segment[-overlap_len:] *= fade_out
                     
                # å åŠ åˆ°ä¸»æ•°ç»„ (Overlap-Add)
                write_len = min(segment_len, len(combined_audio) - start)
                if write_len > 0:
                    combined_audio[start : start + write_len] += this_segment[:write_len]
            
            # æˆªå–æœ‰æ•ˆé•¿åº¦å¹¶èµ‹å€¼
            final_valid_len = min(len(combined_audio), target_samples)
            # æ‰¾åˆ°æœ€åä¸€ä¸ªéé›¶ç‚¹çš„é™„è¿‘ï¼Œæˆ–è€…ç›´æ¥ç”¨ target_samples
            audio_data = combined_audio[:final_valid_len]

        # 4. æœ€ç»ˆæ£€æŸ¥ä¸ä¿å­˜
        # æ£€æŸ¥ NaN / Inf
        if np.isnan(audio_data).any() or np.isinf(audio_data).any():
            print("âŒ æ£€æµ‹åˆ° NaN æˆ– Inf æ•°å€¼ï¼æ›¿æ¢ä¸º 0...")
            audio_data = np.nan_to_num(audio_data)
            
        print(f"ğŸ” éŸ³é¢‘æ•°æ®æ£€æŸ¥: Min={audio_data.min()}, Max={audio_data.max()}")
        
        # å½’ä¸€åŒ–
        max_val = np.max(np.abs(audio_data))
        if max_val > 0:
            audio_data = audio_data / max_val
            
        # æœ€ç»ˆè½¬æ¢ä¸º Int16 (æ ‡å‡† WAV)
        audio_data_int16 = (audio_data * 32767).clip(-32768, 32767).astype(np.int16)
        scipy.io.wavfile.write(output_file, rate=sampling_rate, data=audio_data_int16)
        
        # éªŒè¯æ–‡ä»¶
        if not os.path.exists(output_file) or os.path.getsize(output_file) == 0:
            raise FileNotFoundError("éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¤±è´¥")
        
        print(f"âœ… åå°ç”Ÿæˆå®Œæˆ: {file_id}, å¤§å°: {os.path.getsize(output_file)}")
        music_generation_status = {
            'status': 'completed',
            'file_id': file_id,
            'error': None
        }
        
    except Exception as e:
        print(f"âŒ åå°ç”Ÿæˆå‡ºé”™: {e}")
        music_generation_status = {
            'status': 'failed',
            'file_id': None,
            'error': str(e)
        }

@app.route('/api/generate-music', methods=['POST'])
def generate_music():
    global music_generation_status
    
    # æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
    if music_generation_status['status'] == 'processing':
         return jsonify({
             'status': 'processing', 
             'message': 'ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­'
         }), 200 # å¹‚ç­‰è¿”å› 200

    # é‡ç½®çŠ¶æ€
    music_generation_status = {'status': 'processing', 'file_id': None, 'error': None}
    
    try:
        # æ¨¡å‹åŠ è½½æ£€æŸ¥
        if not model_loaded:
             return jsonify({'error': 'æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­'}), 503

        # ç”Ÿæˆ Prompt
        from stress import get_stress_music_prompt
        input_text = get_stress_music_prompt()
        
        # å¯åŠ¨åå°çº¿ç¨‹
        thread = threading.Thread(target=generate_music_task, args=(input_text,))
        thread.start()
        
        return jsonify({
            'success': True,
            'status': 'processing', 
            'message': 'éŸ³ä¹ç”Ÿæˆä»»åŠ¡å·²åœ¨åå°å¯åŠ¨'
        })
        
    except Exception as e:
        music_generation_status['status'] = 'failed'
        return jsonify({'error': str(e)}), 500

@app.route('/api/music-status', methods=['GET'])
def get_music_status():
    return jsonify(music_generation_status)

@app.route('/api/audio/<file_id>')
def get_audio(file_id):
    """è·å–ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶"""
    try:
        file_path = os.path.join(AUDIO_DIR, f"{file_id}.wav")
        if os.path.exists(file_path):
            return send_file(file_path, as_attachment=False)
        else:
            return jsonify({'error': 'éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        return jsonify({'error': f'è·å–éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}'}), 500

# åˆ é™¤é‡å¤çš„ /api/model-status è·¯ç”±å®šä¹‰
# ä¿ç•™ä¸Šé¢ç¬¬275è¡Œå¼€å§‹çš„æ”¹è¿›ç‰ˆæœ¬

@app.route('/api/set-preference', methods=['POST'])
def set_preference():
    """è®¾ç½®ç”¨æˆ·éŸ³ä¹åå¥½ï¼ˆæµè¡Œ/æ‘‡æ»š/å¤å…¸ï¼‰ï¼Œæ›´æ–°è¿è¡Œæ—¶çš„ STRESS_MUSIC_MAP å¹¶æŒä¹…åŒ–åˆ° stress.pyã€‚"""
    try:
        if not request.is_json:
            return jsonify({'error':'è¯·æ±‚å¿…é¡»æ˜¯JSONæ ¼å¼'}), 400
        data = request.get_json()
        pref = data.get('preference')
        if not pref:
            return jsonify({'error':'æœªæä¾› preference å­—æ®µ'}), 400

        ok, msg = update_and_persist_preference(pref)
        if ok:
            return jsonify({'success': True, 'preference': msg})
        else:
            return jsonify({'success': False, 'error': msg}), 500
    except Exception as e:
        return jsonify({'error': str(e)}), 500
@app.route('/api/latest-hrv')
def latest_hrv():
    """è¿”å› generated_audio/latest_hrv.txt çš„å€¼å’Œä¿®æ”¹æ—¶é—´ï¼ˆè‹¥å­˜åœ¨ï¼‰ã€‚"""
    try:
        latest_hrv_path = os.path.join(os.path.dirname(__file__), 'generated_audio', 'latest_hrv.txt')
        if not os.path.exists(latest_hrv_path):
            return jsonify({'exists': False, 'hrv': None, 'mtime': None})
        mtime = os.path.getmtime(latest_hrv_path)
        with open(latest_hrv_path, 'r', encoding='utf-8') as f:
            txt = f.read().strip()
        try:
            hrv = float(txt)
        except Exception:
            hrv = None
        return jsonify({'exists': True, 'hrv': hrv, 'mtime': mtime})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/confirm-preference', methods=['POST'])
def confirm_preference():
    """åœ¨å‰ç«¯ç¡®è®¤åå¥½æ—¶ï¼š1) æ›´æ–°å¹¶æŒä¹…åŒ– STRESS_MUSIC_MAPï¼Œ2) å¯åŠ¨ hrv_watcher.py è¿›ç¨‹ã€‚
    è¯·æ±‚ä½“: { 'preference': 'æµè¡Œ' }
    """
    try:
        if not request.is_json:
            return jsonify({'error':'è¯·æ±‚å¿…é¡»æ˜¯JSONæ ¼å¼'}), 400
        data = request.get_json()
        pref = data.get('preference')
        if not pref:
            return jsonify({'error':'æœªæä¾› preference å­—æ®µ'}), 400

        ok, msg = update_and_persist_preference(pref)
        # å¦‚æœæŒä¹…åŒ–å¤±è´¥ï¼Œä»ç„¶è¿”å›æˆåŠŸå“åº”ç  200ï¼Œè®©å‰ç«¯å†³å®šæ˜¯å¦ç»§ç»­ç”ŸæˆéŸ³ä¹ã€‚
        # å‰ç«¯æœ‰å¤„ç†ï¼šè‹¥ success=false åˆ™æ˜¾ç¤ºæç¤ºä½†ç»§ç»­ç”Ÿæˆã€‚
        if not ok:
            return jsonify({'success': False, 'error': msg, 'preference': msg})

        # ä¸å†è‡ªåŠ¨å¯åŠ¨ watcherï¼›å‰ç«¯ä¼šåœ¨ç¡®è®¤åè§¦å‘ç”Ÿæˆ
        return jsonify({'success': True, 'preference': msg})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/start-measurement', methods=['POST'])
def start_measurement():
    """å¯åŠ¨ hrv_reader.py æµ‹é‡è¿›ç¨‹ã€‚æ¥æ”¶ JSON: { "port": "/dev/tty...", "baud": 115200, "window": 30 }
    å¦‚æœå·²æœ‰æµ‹é‡åœ¨è¿è¡Œï¼Œåˆ™è¿”å›å½“å‰çŠ¶æ€ã€‚"""
    try:
        global measurement_state
        if measurement_state.get('running'):
            return jsonify({'started': False, 'reason': 'measurement_running'}), 409

        data = request.get_json() or {}
        port = data.get('port', '/dev/tty.usbmodem2017_2_251')
        baud = int(data.get('baud', 115200))
        window = int(data.get('window', 30))

        # åŸºæœ¬æ ¡éªŒï¼ˆåªå…è®¸ä»¥ /dev/ å¼€å¤´çš„ä¸²å£è·¯å¾„ä»¥é˜²æ»¥ç”¨ï¼‰
        if not isinstance(port, str) or not port.startswith('/dev/'):
            return jsonify({'error': 'invalid port'}), 400

        # æ£€æŸ¥ hrv_reader.py æ˜¯å¦å­˜åœ¨
        script_path = os.path.join(os.path.dirname(__file__), 'hrv_reader.py')
        if not os.path.exists(script_path):
            return jsonify({'started': False, 'reason': 'hrv_reader_missing', 'error': f'æ‰¾ä¸åˆ° {script_path}'}), 500

        # ä¸å†åœ¨æ­¤å¤„ä¸¥æ ¼æ£€æŸ¥ä¸²å£æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚
        # åœ¨å¾ˆå¤šå¼€å‘/æµ‹è¯•ç¯å¢ƒä¸‹ï¼Œè®¾å¤‡æ–‡ä»¶ä¸å¯ç”¨ï¼Œä½†æˆ‘ä»¬å¸Œæœ›ä»èƒ½å¯åŠ¨æµ‹é‡çº¿ç¨‹è®©è„šæœ¬è‡ªè¡ŒæŠ¥é”™æˆ–é‡è¯•ã€‚
        # å¦‚æœéœ€è¦æ›´ä¸¥æ ¼çš„æ ¡éªŒï¼Œå¯ä»¥åœ¨å‰ç«¯æˆ–é…ç½®ä¸­å¯ç”¨ã€‚

        # æ„å»ºå‘½ä»¤ï¼šä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨æ‰§è¡Œè„šæœ¬
        cmd = [sys.executable, script_path, '--port', port, '--baud', str(baud), '--window', str(window)]

        # æ¸…ç†æ—§çŠ¶æ€å¹¶å¯åŠ¨çº¿ç¨‹
        measurement_state = {'running': True, 'finished': False, 'error': None, 'output': ''}
        thread = threading.Thread(target=_run_measurement_in_thread, args=(cmd, measurement_state), daemon=True)
        try:
            thread.start()
        except Exception as e:
            measurement_state.update({'running': False, 'finished': True, 'error': str(e)})
            return jsonify({'started': False, 'reason': 'thread_start_failed', 'error': str(e)}), 500

        return jsonify({'started': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/measurement-status')
def measurement_status():
    """è¿”å›å½“å‰æµ‹é‡çŠ¶æ€ï¼ˆrunning/finished/error å’Œè¾“å‡ºç‰‡æ®µï¼‰"""
    try:
        global measurement_proc
        
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
        is_running = False
        if measurement_proc is not None:
            if measurement_proc.poll() is None:
                is_running = True
            else:
                # è¿›ç¨‹å·²ç»“æŸ
                measurement_proc = None
        
        # åªè¿”å›å¿…è¦å­—æ®µï¼Œé¿å…è¿‡å¤§è¾“å‡º
        s = {
            'running': is_running or measurement_state.get('running', False),
            'finished': measurement_state.get('finished', False),
            'error': measurement_state.get('error'),
            'output_tail': (measurement_state.get('output') or '')[-1000:]
        }
        return jsonify(s)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/storage-status')
def storage_status():
    """è·å–å­˜å‚¨çŠ¶æ€"""
    try:
        if not os.path.exists(AUDIO_DIR):
            return jsonify({
                'total_files': 0,
                'total_size_mb': 0,
                'max_files': MAX_AUDIO_FILES,
                'retention_hours': AUDIO_RETENTION_HOURS
            })
        
        files = os.listdir(AUDIO_DIR)
        audio_files = [f for f in files if f.endswith('.wav')]
        
        total_size = 0
        for file in audio_files:
            file_path = os.path.join(AUDIO_DIR, file)
            total_size += os.path.getsize(file_path)
        
        return jsonify({
            'total_files': len(audio_files),
            'total_size_mb': round(total_size / (1024 * 1024), 2),
            'max_files': MAX_AUDIO_FILES,
            'retention_hours': AUDIO_RETENTION_HOURS
        })
    except Exception as e:
        return jsonify({'error': f'è·å–å­˜å‚¨çŠ¶æ€å¤±è´¥: {str(e)}'}), 500

@app.route('/api/cleanup-files', methods=['POST'])
def cleanup_files():
    """æ‰‹åŠ¨æ¸…ç†æ–‡ä»¶"""
    try:
        cleanup_old_files()
        return jsonify({'success': True, 'message': 'æ–‡ä»¶æ¸…ç†å®Œæˆ'})
    except Exception as e:
        return jsonify({'error': f'æ¸…ç†æ–‡ä»¶å¤±è´¥: {str(e)}'}), 500


@app.route('/api/simulate-hrv', methods=['POST'])
def simulate_hrv():
    """ç”¨äºæœ¬åœ°è°ƒè¯•ï¼šå†™å…¥ generated_audio/latest_hrv.txt å¹¶è¿”å›æ–°å€¼ã€‚
    è¯·æ±‚ JSON: { 'hrv': 32.5 }
    ä»…åœ¨å¼€å‘ç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œç”Ÿäº§åº”ç¦ç”¨æ­¤ç«¯ç‚¹ã€‚
    """
    try:
        if not request.is_json:
            return jsonify({'error': 'è¯·æ±‚å¿…é¡»ä¸º JSON'}), 400
        data = request.get_json()
        hrv = data.get('hrv')
        if hrv is None:
            return jsonify({'error': 'æœªæä¾› hrv å­—æ®µ'}), 400
        try:
            hrv_val = float(hrv)
        except Exception:
            return jsonify({'error': 'hrv å¿…é¡»ä¸ºæ•°å­—'}), 400

        latest_hrv_path = os.path.join(os.path.dirname(__file__), 'generated_audio', 'latest_hrv.txt')
        os.makedirs(os.path.dirname(latest_hrv_path), exist_ok=True)
        with open(latest_hrv_path, 'w', encoding='utf-8') as f:
            f.write(f"{hrv_val:.4f}")

        return jsonify({'success': True, 'hrv': hrv_val})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/get-stress-map')
def get_stress_map():
    """åªè¯»ï¼šè¿”å›å½“å‰è¿è¡Œæ—¶çš„ STRESS_MUSIC_MAPï¼Œä¾¿äºå‰ç«¯æˆ–æµ‹è¯•è„šæœ¬éªŒè¯åå¥½å·²å†™å…¥å†…å­˜/æ–‡ä»¶ã€‚"""
    try:
        # ç›´æ¥è¿”å›è¿è¡Œæ—¶å†…å­˜ä¸­çš„æ˜ å°„
        return jsonify({'success': True, 'stress_map': STRESS_MUSIC_MAP})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

if __name__ == '__main__':
    # æ¸…ç©º latest_hrv.txt æ–‡ä»¶
    latest_hrv_path = os.path.join(os.path.dirname(__file__), 'generated_audio', 'latest_hrv.txt')
    try:
        os.makedirs(os.path.dirname(latest_hrv_path), exist_ok=True)
        # æ¸…ç©ºæ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœæ–‡ä»¶å­˜åœ¨åˆ™æ¸…ç©ºï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºç©ºæ–‡ä»¶ï¼‰
        with open(latest_hrv_path, 'w', encoding='utf-8') as f:
            f.write('')
        print(f"âœ… å·²æ¸…ç©º latest_hrv.txt æ–‡ä»¶")
    except Exception as e:
        print(f"âš ï¸  æ¸…ç©º latest_hrv.txt æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    app.run(debug=True, host='0.0.0.0', port=5001)